---
title: "4620 Final Project"
author: "Group_2"
date: "2022-11-20"
output: html_document
---

```{r}
library(readr)
library(tidymodels)
library("DataExplorer")
library("xgboost")
library("data.table")
library("mltools")
library("glmnet")
library("ggplot2")
library(psych)
```


## Part I: Exploratory Data Analysis
### Check data - (1) Basic information about data
```{r}
train <- read.csv("train.csv", header=TRUE)
test <- read.csv("test_new.csv", header=TRUE)

print(dim(train))
print(dim(test))
print("Basic information for training dataset")
print(is.data.frame(train))
print(ncol(train))
print(nrow(train))

print("Basic information for training dataset")
print(is.data.frame(test))
print(ncol(test))
print(nrow(test))

str(train)
```


### Check data - (2) data type
We have two types of variables: 52 Categorical variables, and 28 Numeric variables.

Categorical variables (52)
-- Nominal (27)
-- Ordinal (25)

Nominal (27): MSSubClass, MSZoning, Street, Alley, LotShape, LandContour, Utilities, LotConfig, Neighborhood, Condition1, Condition2, BldgType, HouseStyle, RoofStyle, CentralAir, RoofMatl, Exterior1st, Exterior2nd, MasVnrType, Foundation, Heating, Functional, GarageType, Fence, MiscFeature, SaleType, SaleCondition. 

Ordinal (25): id, LandSlope, OverallQual, OverallCond, YearBuilt, YearRemodAdd, ExterQual, ExterCond, BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2, HeatingQC, Electrical, KitchenQual, FireplaceQu, GarageYrBlt, GarageFinish, GarageQual, GarageCond, PoolQC, MoSold, YrSold, PavedDrive.

Numeric variables (28): LotFrontage, LotArea, MasVnrArea, BsmtFinSF1, BsmtFinSF2, BsmtUnfSF, TotalBsmtSF, 1stFlrSF, 2ndFlrSF, LowQualFinSF, GrLivArea, BsmtFullBath, BsmtHalfBath, FullBath, HalfBath, Bedroom, Kitchen, TotRmsAbvGrd, Fireplaces, GarageCars, GarageArea, WoodDeckSF, OpenPorchSF, EnclosedPorch, 3SsnPorch, ScreenPorch, PoolArea, MiscVal. 

```{r}
# check data type
# find categorical and numerica variables
category_col = c("Id", "LandSlope", "OverallQual", "OverallCond", "YearBuilt", "YearRemodAdd", "ExterQual", "ExterCond", "BsmtQual", "BsmtCond", "BsmtExposure", "BsmtFinType1", "BsmtFinType2", "HeatingQC", "Electrical", "KitchenQual", "FireplaceQu", "GarageYrBlt", "GarageFinish", "GarageQual", "GarageCond", "PoolQC", "MoSold", "YrSold", "PavedDrive", "MSSubClass", "MSZoning", "Street", "Alley", "LotShape", "LandContour", "Utilities", "LotConfig", "Neighborhood", "Condition1", "Condition2", "BldgType", "HouseStyle", "RoofStyle", "CentralAir", "RoofMatl", "Exterior1st", "Exterior2nd", "MasVnrType", "Foundation", "Heating", "Functional", "GarageType", "Fence", "MiscFeature", "SaleType", "SaleCondition")
numeric_col = c("LotFrontage", "LotArea", "MasVnrArea", "BsmtFinSF1", "BsmtFinSF2", "BsmtUnfSF", "TotalBsmtSF", "X1stFlrSF", "X2ndFlrSF", "LowQualFinSF", "GrLivArea", "BsmtFullBath", "BsmtHalfBath", "FullBath", "HalfBath", "BedroomAbvGr", "KitchenAbvGr", "TotRmsAbvGrd", "Fireplaces", "GarageCars", "GarageArea", "WoodDeckSF", "OpenPorchSF", "EnclosedPorch", "X3SsnPorch", "ScreenPorch", "PoolArea", "MiscVal") 
# change the type of variable
train = train %>% mutate_at(category_col, as.character)
train = train %>% mutate_at(numeric_col, as.integer)

# check whether the type is changed successfully
str(train)
```

##### ??????????? 加comment



### Check data - (3) duplicate / null value
```{r}
# check number of duplicated records
sum(duplicated(train))

# check number/percentage of NA data
na_per = c()
col_names = c()
for (i in 2: 80) {
  if (sum(is.na(train[,i]))/dim(train)[1]*100 > 0) {
    na_per = append(na_per, sum(is.na(train[,i]))/dim(train)[1]*100)
    col_names = append(col_names, colnames(train)[i])
  cat(sprintf("%s \n # of NA: %d, Percentage: %.2f%% \n", colnames(train)[i],   sum(is.na(train[,i])), sum(is.na(train[,i]))/dim(train)[1]*100))
  }
}

# draw the visualization to see percentage of NA
df = as.data.frame(col_names, na_per)
pt = ggplot(data = df, aes(x = na_per, y = col_names)) +
      geom_bar(stat="identity") +
      labs(x = "Percentage of Null Data (%)", y = "")
pt
```

In the Data Processing section, we first checked the duplicated records and found there is no duplicated records. Then, we check the number and percentage of null values for each variable. We built a visualization for the variable with null values. After checking the data, we found that NA does only only stands for the missing data. For some variables, NA means "No". Thus, we replaced the "NA" of these variables with "No" instead.

##### ??????????? 加comment

```{r}
train <- train %>% mutate_if(is.numeric, ~replace_na(., 0))
train <- train %>% mutate_if(is.character, ~replace_na(., "No"))
test <- test %>% mutate_if(is.numeric, ~replace_na(., 0))
test <- test %>% mutate_if(is.character, ~replace_na(., "No"))
print(dim(train))
print(dim(test))

head(train)
```

### EDA - corr
```{r}
num_data <- subset(train, select = c(LotFrontage, LotArea, MasVnrArea, BsmtFinSF1, BsmtFinSF2, BsmtUnfSF, TotalBsmtSF, X1stFlrSF, X2ndFlrSF, LowQualFinSF, GrLivArea, BsmtFullBath, BsmtHalfBath, FullBath, HalfBath, BedroomAbvGr, KitchenAbvGr, TotRmsAbvGrd, Fireplaces, GarageCars, GarageArea, WoodDeckSF, OpenPorchSF, EnclosedPorch, X3SsnPorch, ScreenPorch, PoolArea, MiscVal, SalePrice))

# Correlation between numerical data 
cor(num_data)
```
From the correlation graph above, we can clearly find that [BsmtFinSF1, BsmtFullBath], [TotalBsmtSF, X1stFlrSF], [GrLivArea, X2ndFlrSF], [GrLivArea, TotRmsAbvGrd] have appear to be potentially problematic collinearity amongst the predictor variables.


### EDA - graph

```{r}
dim(train)
```

There are 1460 observations and 81 variables in the training data set.


First, lets's start to explore the response - Sale Price (in dollars).


```{r}
ggplot(train, aes(x = SalePrice)) + 
  geom_histogram(bins = 50, col= "white") 
```

The plot is right-skewed, which means that there is less expensive house than inexpensive ones.


```{r}
summary(train$SalePrice)
```

The median of Sale Price of the houses is $163000.
The mean of Sale Price of the houses is $180921.
The least expensive house is $34900.
The most expensive house is $755000.


Next, to investigate if there are early signs of variables are likely to be significant in predicting response. First, lets's look at those numeric variables.

```{r}
cor(train[,unlist(lapply(train, is.numeric))])
```

From the last part, we find that the variables $TotalBsmtSF$, $1stFlrSF$, $GrLivArea$ have strong correlation with the response $SalePrice$.

```{r}
strong_collearity <- subset(data.train, select = c(TotalBsmtSF, X1stFlrSF, GrLivArea, SalePrice))
pairs.panels(strong_collearity)
```

From the plot, we can verify that all of these three variables $TotalBsmtSF$ (Total square feet of basement area), $1stFlrSF$ (First Floor square feet), $GrLivArea$ (Above grade (ground) living area square feet) have strong positive correlation with the response $SalePrice$. In other words, as each of these three factors (Total square feet of basement area / First Floor square feet / Above grade (ground) living area square feet) increasing, $SalePrice$ will get increase.



In addition, we would also explore those categorical variables that might be useful for predicting the response. 

$OverallQual$:

```{r}
overallQual <- as.numeric(train$OverallQual)
cor(overallQual, train$SalePrice)
```

Thus, $OverallQual$ has a strong positive correlation with the $SalePrice$.


```{r}
ggplot(train, aes(x=overallQual,y=SalePrice)) + geom_point(shape=20) + geom_smooth(method="lm", color = "red")+ scale_y_continuous(labels=comma)
```

This plot verifies that $OverallQual$ has a strong positive correlation with the $SalePrice$.


```{r}
train$OverallQual=as.factor(train$OverallQual)
train%>%ggplot(aes(x=OverallQual,y=SalePrice))+geom_violin(aes(fill=OverallQual))
```

OverallQual: Rates the overall material and finish of the house.

       10	Very Excellent
       9	Excellent
       8	Very Good
       7	Good
       6	Above Average
       5	Average
       4	Below Average
       3	Fair
       2	Poor
       1	Very Poor



From the colorful plot, we can find that as Rates the overall material and finish of the house increasing, the sale price of the house gets increased. Besides, if the rates the overall material and finish of the house is below average, the sale price varies for the largest range other than that of other rates. In addition, there is no big difference of the mean sale price of house at rate = 6 and rate = 7.



Also, we can find that $Neighboorhood$ is also a good predictor for its positive strong correlation with $SalePrice$.

```{r}
cor(train$TotalBsmtSF , train$SalePrice)
```

```{r}
ggplot(train, aes(x=Neighborhood,y=SalePrice)) + geom_boxplot(fill="light blue", color="black")+
theme(axis.text.x=element_text(angle = 90)) + scale_y_continuous(labels=comma)
                                            # change the scale from e-x type into real number
```

The neighborhoods of the house plays a significant role in the sale price. We can see that the houses around MeadowV were sold at the least expensive price, while those besides StroneBr were sold at the most expensive price. For houses' neighborhood is NoRidge, there are some of the most expensive price.


Moreover, for the $GarageCars$, we would like to explore by plotting.

```{r}
train$GarageCars=as.factor(train$GarageCars)
train%>%ggplot(aes(x=GarageCars,y=SalePrice))+geom_violin(aes(fill=GarageCars))
```

We can see that for the house of size of garage in car capacity as 3, the sale price is the highest, while the houses with size of garage in car capacity as 0 have the most inexpensive sale price.

At last, we infer that the age of house might be an important predictor.

House's age since being built (2022-YearBuilt):

```{r}
year <- as.numeric(train$YearBuilt)
AgeHouse <- 2022 - year
```

```{r}
cor(AgeHouse, train$SalePrice)
```

It shows that there is strong negative correlation between the age of house and the sale price.

```{r}
ggplot(train, aes(x=AgeHouse,y=SalePrice)) + geom_point(shape=20) + geom_smooth(method="lm", color = "red")+ scale_y_continuous(labels=comma)
```

As the age of house increases, the sale price will get decreasing.


In breif, based on the EDA, there are lots of variables having weak correlation with the response. Thus, we would like to choose the LASSO and ridge regression for modeling.
